<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 Reliability study designs | Psychological Testing</title>
  <meta name="description" content="PSY 362: Psychological Testing" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="6 Reliability study designs | Psychological Testing" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://r-computing-lab.github.io/Testing4Psych" />
  <meta property="og:image" content="https://r-computing-lab.github.io/Testing4Psychassets/logo.png" />
  <meta property="og:description" content="PSY 362: Psychological Testing" />
  <meta name="github-repo" content="DataScience4Psych/Testing4Psych" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 Reliability study designs | Psychological Testing" />
  <meta name="twitter:site" content="@smasongarrison" />
  <meta name="twitter:description" content="PSY 362: Psychological Testing" />
  <meta name="twitter:image" content="https://r-computing-lab.github.io/Testing4Psychassets/logo.png" />

<meta name="author" content="S. Mason Garrison" />


<meta name="date" content="2021-02-27" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="assets/favicon.ico" type="image/x-icon" />
<link rel="prev" href="r-code-and-readings-for-module-6.html"/>
<link rel="next" href="good-resources.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-3.5.1/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<link href="libs/vembedr-0.1.4/css/vembedr.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.17/datatables.js"></script>
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="libs/nouislider-7.0.10/jquery.nouislider.min.css" rel="stylesheet" />
<script src="libs/nouislider-7.0.10/jquery.nouislider.min.js"></script>
<link href="libs/selectize-0.12.0/selectize.bootstrap3.css" rel="stylesheet" />
<script src="libs/selectize-0.12.0/selectize.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<script src="libs/twitter-widget-0.0.1/widgets.js"></script>
<html>

  <head>
  <script src="anchor-links.js"></script>

  <!-- Global site tag (gtag.js) - Google Analytics
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-68219208-1"></script>

  <script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-68219208-1');
  </script>
   -->
  </head>

</html>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="assets/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="toc-logo"><a href="./"><img src="assets/logo.png" style="border-radius: 00%;" ></a></li>

<li class="divider"></li>
<li class="part"><span><b>Front Matter</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome to PSY 362</a></li>
<li class="chapter" data-level="" data-path="attribution.html"><a href="attribution.html"><i class="fa fa-check"></i>Attribution</a>
<ul>
<li class="chapter" data-level="" data-path="attribution.html"><a href="attribution.html#major-additional-attributions"><i class="fa fa-check"></i>Major &amp; Additional Attributions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="license.html"><a href="license.html"><i class="fa fa-check"></i>License</a></li>
<li class="chapter" data-level="" data-path="colophon.html"><a href="colophon.html"><i class="fa fa-check"></i>Colophon</a></li>
<li class="chapter" data-level="" data-path="public-health-dashboards.html"><a href="public-health-dashboards.html"><i class="fa fa-check"></i>Public Health Dashboards</a>
<ul>
<li class="chapter" data-level="" data-path="public-health-dashboards.html"><a href="public-health-dashboards.html#wake-forest"><i class="fa fa-check"></i>Wake Forest</a></li>
<li class="chapter" data-level="" data-path="public-health-dashboards.html"><a href="public-health-dashboards.html#forsyth-county"><i class="fa fa-check"></i>Forsyth County</a>
<ul>
<li class="chapter" data-level="" data-path="public-health-dashboards.html"><a href="public-health-dashboards.html#vaccinations"><i class="fa fa-check"></i>Vaccinations</a></li>
<li class="chapter" data-level="" data-path="public-health-dashboards.html"><a href="public-health-dashboards.html#case-counts"><i class="fa fa-check"></i>Case Counts</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="public-health-dashboards.html"><a href="public-health-dashboards.html#north-carolina"><i class="fa fa-check"></i>North Carolina</a></li>
</ul></li>
<li class="part"><span><b>I Module 05</b></span></li>
<li class="chapter" data-level="1" data-path="meet-our-toolbox.html"><a href="meet-our-toolbox.html"><i class="fa fa-check"></i><b>1</b> Meet our toolbox!</a>
<ul>
<li class="chapter" data-level="1.1" data-path="meet-our-toolbox.html"><a href="meet-our-toolbox.html#r"><i class="fa fa-check"></i><b>1.1</b> R</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="meet-our-toolbox.html"><a href="meet-our-toolbox.html#install"><i class="fa fa-check"></i><b>1.1.1</b> Install R and RStudio</a></li>
<li class="chapter" data-level="1.1.2" data-path="meet-our-toolbox.html"><a href="meet-our-toolbox.html#testing-testing"><i class="fa fa-check"></i><b>1.1.2</b> Testing testing</a></li>
<li class="chapter" data-level="1.1.3" data-path="meet-our-toolbox.html"><a href="meet-our-toolbox.html#add-on-packages"><i class="fa fa-check"></i><b>1.1.3</b> Add-on packages</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="meet-our-toolbox.html"><a href="meet-our-toolbox.html#getting-help-with-r"><i class="fa fa-check"></i><b>1.2</b> Getting Help with R</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="meet-our-toolbox.html"><a href="meet-our-toolbox.html#further-resources"><i class="fa fa-check"></i><b>1.2.1</b> Further resources</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="r-basics.html"><a href="r-basics.html"><i class="fa fa-check"></i><b>2</b> R basics and workflows</a>
<ul>
<li class="chapter" data-level="2.1" data-path="r-basics.html"><a href="r-basics.html#introducing-functions"><i class="fa fa-check"></i><b>2.1</b> Introducing Functions</a></li>
<li class="chapter" data-level="2.2" data-path="r-basics.html"><a href="r-basics.html#introduction-to-objects"><i class="fa fa-check"></i><b>2.2</b> Introduction to Objects</a></li>
<li class="chapter" data-level="2.3" data-path="r-basics.html"><a href="r-basics.html#workspace-and-working-directory"><i class="fa fa-check"></i><b>2.3</b> Workspace and working directory</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="r-basics.html"><a href="r-basics.html#workspace-.rdata"><i class="fa fa-check"></i><b>2.3.1</b> Workspace, <code>.RData</code></a></li>
<li class="chapter" data-level="2.3.2" data-path="r-basics.html"><a href="r-basics.html#working-directory"><i class="fa fa-check"></i><b>2.3.2</b> Working directory</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="r-basics.html"><a href="r-basics.html#rprojs"><i class="fa fa-check"></i><b>2.4</b> RStudio projects</a></li>
<li class="chapter" data-level="2.5" data-path="r-basics.html"><a href="r-basics.html#saving-files-and-protips"><i class="fa fa-check"></i><b>2.5</b> Saving Files and Protips</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="refreshers-and-examples.html"><a href="refreshers-and-examples.html"><i class="fa fa-check"></i><b>3</b> Refreshers and Examples</a>
<ul>
<li class="chapter" data-level="3.1" data-path="refreshers-and-examples.html"><a href="refreshers-and-examples.html#some-terms"><i class="fa fa-check"></i><b>3.1</b> Some terms</a></li>
<li class="chapter" data-level="3.2" data-path="refreshers-and-examples.html"><a href="refreshers-and-examples.html#summary-statistics"><i class="fa fa-check"></i><b>3.2</b> Summary Statistics</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="r-code-for-module-5.html"><a href="r-code-for-module-5.html"><i class="fa fa-check"></i><b>4</b> R Code for Module 5</a>
<ul>
<li class="chapter" data-level="4.1" data-path="r-code-for-module-5.html"><a href="r-code-for-module-5.html#simulate-a-constant-true-score"><i class="fa fa-check"></i><b>4.1</b> Simulate a constant true score</a></li>
<li class="chapter" data-level="4.2" data-path="r-code-for-module-5.html"><a href="r-code-for-module-5.html#pisa-total-reading-scores-with-simulated-error-and-true-scores-based-on-ctt"><i class="fa fa-check"></i><b>4.2</b> PISA total reading scores with simulated error and true scores based on CTT</a></li>
<li class="chapter" data-level="4.3" data-path="r-code-for-module-5.html"><a href="r-code-for-module-5.html#reliability-and-unreliability-illustrated"><i class="fa fa-check"></i><b>4.3</b> Reliability and unreliability Illustrated</a></li>
</ul></li>
<li class="part"><span><b>II Module 06</b></span></li>
<li class="chapter" data-level="5" data-path="r-code-and-readings-for-module-6.html"><a href="r-code-and-readings-for-module-6.html"><i class="fa fa-check"></i><b>5</b> R Code and Readings for Module 6</a>
<ul>
<li class="chapter" data-level="5.1" data-path="r-code-and-readings-for-module-6.html"><a href="r-code-and-readings-for-module-6.html#statistical-definition-of-reliability."><i class="fa fa-check"></i><b>5.1</b> Statistical definition of reliability.</a></li>
<li class="chapter" data-level="5.2" data-path="r-code-and-readings-for-module-6.html"><a href="r-code-and-readings-for-module-6.html#estimating-reliability"><i class="fa fa-check"></i><b>5.2</b> Estimating reliability</a></li>
<li class="chapter" data-level="5.3" data-path="r-code-and-readings-for-module-6.html"><a href="r-code-and-readings-for-module-6.html#split-half-method"><i class="fa fa-check"></i><b>5.3</b> Split-half method</a></li>
<li class="chapter" data-level="5.4" data-path="r-code-and-readings-for-module-6.html"><a href="r-code-and-readings-for-module-6.html#spearman-brown"><i class="fa fa-check"></i><b>5.4</b> Spearman Brown</a></li>
<li class="chapter" data-level="5.5" data-path="r-code-and-readings-for-module-6.html"><a href="r-code-and-readings-for-module-6.html#sem"><i class="fa fa-check"></i><b>5.5</b> SEM</a></li>
<li class="chapter" data-level="5.6" data-path="r-code-and-readings-for-module-6.html"><a href="r-code-and-readings-for-module-6.html#interpreting-reliability-and-unreliability"><i class="fa fa-check"></i><b>5.6</b> Interpreting reliability and unreliability</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="reliability-study-designs.html"><a href="reliability-study-designs.html"><i class="fa fa-check"></i><b>6</b> Reliability study designs</a>
<ul>
<li class="chapter" data-level="6.1" data-path="reliability-study-designs.html"><a href="reliability-study-designs.html#interrater-reliability"><i class="fa fa-check"></i><b>6.1</b> Interrater reliability</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="reliability-study-designs.html"><a href="reliability-study-designs.html#proportion-agreement"><i class="fa fa-check"></i><b>6.1.1</b> Proportion agreement</a></li>
<li class="chapter" data-level="6.1.2" data-path="reliability-study-designs.html"><a href="reliability-study-designs.html#kappa-agreement"><i class="fa fa-check"></i><b>6.1.2</b> Kappa agreement</a></li>
<li class="chapter" data-level="6.1.3" data-path="reliability-study-designs.html"><a href="reliability-study-designs.html#pearson-correlation"><i class="fa fa-check"></i><b>6.1.3</b> Pearson correlation</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="reliability-study-designs.html"><a href="reliability-study-designs.html#summary"><i class="fa fa-check"></i><b>6.2</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>III Other Coolness</b></span></li>
<li class="chapter" data-level="7" data-path="good-resources.html"><a href="good-resources.html"><i class="fa fa-check"></i><b>7</b> Good Resources</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><center>
  <a rel="license" href="./license.html">
    License: CC-BY-SA<br>
    <i class = "fab fa-creative-commons fa-2x"></i>
    <i class = "fab fa-creative-commons-by fa-2x"></i>
    <i class = "fab fa-creative-commons-sa fa-2x"></i>
  </a>
</li></center>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Psychological Testing</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="reliability-study-designs" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Reliability study designs</h1>
<p>Now that we’ve established the more common estimates of reliability and unreliability, we can discuss the four main study designs that allow us to collect data for our estimates. These designs are referred to as internal consistency, equivalence, stability, and equivalence/stability designs. Each design produces a corresponding type of reliability that is expected to be impacted by different sources of measurement error.</p>
<p>The four standard study designs vary in the number of test forms and the number of testing occasions involved in the study. Until now, we’ve been talking about using two test forms on two separate administrations. This study design is found in the lower right corner of Table <a href="reliability-study-designs.html#tab:rdesigns">6.1</a>, and it provides us with an estimate of equivalence (for two different forms of a test) and stability (across two different administrations of the test). This study design has the potential to capture the most sources of measurement error, and it can thus produce the lowest estimate of reliability, because of the two factors involved. The more time that passes between administrations, and as two test forms differ more in their content and other features, the more error we would expect to be introduced. On the other hand, as our two test forms are administered closer in time, we move from the lower right corner to the upper right corner of Table <a href="reliability-study-designs.html#tab:rdesigns">6.1</a>, and our estimate of reliability captures less of the measurement error introduced by the passage of time. We’re left with an estimate of the equivalence between the two forms.</p>
<p>As our test forms become more and more equivalent, we eventually end up with the same test form, and we move to the first column in Table <a href="reliability-study-designs.html#tab:rdesigns">6.1</a>, where one of two types of reliability is estimated. First, if we administer the same test twice with time passing between administrations, we have an estimate of the stability of our measurement over time. Given that the same test is given twice, any measurement error will be due to the passage of time, rather than differences between the test forms. Second, if we administer one test only once, we no longer have an estimate of stability, and we also no longer have an estimate of reliability that is based on correlation. Instead, we have an estimate of what is referred to as the internal consistency of the measurement. This is based on the relationships among the test items themselves, which we treat as miniature alternate forms of the test. The resulting reliability estimate is impacted by error that comes from the items themselves being unstable estimates of the construct of interest.</p>
<table>
<caption><span id="tab:rdesigns">Table 6.1: </span>Four Main Reliability Study Designs</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">1 Form</th>
<th align="left">2 Forms</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1 Occasion</td>
<td align="left">Internal Consistency</td>
<td align="left">Equivalence</td>
</tr>
<tr class="even">
<td align="left">2 Occasions</td>
<td align="left">Stability</td>
<td align="left">Equivalence &amp; Stability</td>
</tr>
</tbody>
</table>
<p>Internal consistency reliability is estimated using either coefficient alpha or split-half reliability. All the remaining cells in Table <a href="reliability-study-designs.html#tab:rdesigns">6.1</a> involve estimates of reliability that are based on correlation coefficients.</p>
<p>Table <a href="reliability-study-designs.html#tab:rdesigns">6.1</a> contains four commonly used reliability study designs. There are others, including designs based on more than two forms or more than two occasions, and designs involving scores from raters, discussed below.</p>
<div id="interrater-reliability" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Interrater reliability</h2>
<blockquote>
<p>It was like listening to three cats getting strangled in an alley.<br />
— Simon Cowell, disparaging a singer on <em>American Idol</em></p>
</blockquote>
<p>Interrater reliability can be considered a specific instance of reliability where inconsistencies are not attributed to differences in test forms, test items, or administration occasions, but to the scoring process itself, where humans, or in some cases computers, contribute as raters. Measurement with raters often involves some form of performance assessment, for example, a stage performance within a singing competition. Judgment and scoring of such a performance by raters introduces additional error into the measurement process. Interrater reliability allows us to examine the negative impact of this error on our results.</p>
<p>Note that rater error is another factor or facet in the measurement process. Because it is another facet of measurement, raters can introduce error above and beyond error coming from sampling of items, differences in test forms, or the passage of time between administrations. This is made explicit within generalizability theory, discussed below. Some simpler methods for evaluating interrater reliability are introduced first.</p>
<div id="proportion-agreement" class="section level3" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Proportion agreement</h3>
<p>The proportion of agreement is the simplest measure of interrater reliability. It is calculated as the total number of times a set of ratings agree, divided by the total number of units of observation that are rated. The strengths of proportion agreement are that it is simple to calculate and it can be used with any type of <em>discrete</em> measurement scale. The major drawbacks are that it doesn’t account for chance agreement between ratings, and it only utilizes the nominal information in a scale, that is, any ordering of values is ignored.</p>
<p>To see the effects of chance, let’s simulate scores from two judges where ratings are completely random, as if scores of 0 and 1 are given according to the flip of a coin. Suppose 0 is tails and 1 is heads. In this case, we would expect two raters to agree a certain proportion of the time by chance alone. The <code>table()</code> function creates a cross-tabulation of frequencies, also known as a crosstab. Frequencies for agreement are found in the diagonal cells, from upper left to lower right, and frequencies for disagreement are found everywhere else.</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="reliability-study-designs.html#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate random coin flips for two raters</span></span>
<span id="cb39-2"><a href="reliability-study-designs.html#cb39-2" aria-hidden="true" tabindex="-1"></a><span class="co"># runif() generates random numbers from a uniform </span></span>
<span id="cb39-3"><a href="reliability-study-designs.html#cb39-3" aria-hidden="true" tabindex="-1"></a><span class="co"># distribution</span></span>
<span id="cb39-4"><a href="reliability-study-designs.html#cb39-4" aria-hidden="true" tabindex="-1"></a>flip1 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">30</span>))</span>
<span id="cb39-5"><a href="reliability-study-designs.html#cb39-5" aria-hidden="true" tabindex="-1"></a>flip2 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">30</span>))</span>
<span id="cb39-6"><a href="reliability-study-designs.html#cb39-6" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(flip1, flip2)</span>
<span id="cb39-7"><a href="reliability-study-designs.html#cb39-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      flip2</span></span>
<span id="cb39-8"><a href="reliability-study-designs.html#cb39-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; flip1 0 1</span></span>
<span id="cb39-9"><a href="reliability-study-designs.html#cb39-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     0 5 8</span></span>
<span id="cb39-10"><a href="reliability-study-designs.html#cb39-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     1 9 8</span></span></code></pre></div>
<p>Let’s find the proportion agreement for the simulated coin flip data. The question we’re answering is, how often did the coin flips have the same value, whether 0 or 1, for both raters across the 30 tosses? The crosstab shows this agreement in the first row and first column, with raters both flipping tails 5 times, and in the second row and second column, with raters both flipping heads 8 times. We can add these up to get 13, and divide by <span class="math inline">\(n = 30\)</span> to get the percentage agreement.</p>
<p>Data for the next few examples were simulated to represent scores given by two raters with a certain correlation, that is, a certain reliability. Thus, agreement here isn’t simply by chance. In the population, scores from these raters correlated at 0.90. The score scale ranged from 0 to 6 points, with means set to 4 and 3 points for the raters 1 and 2, and SD of 1.5 for both. We’ll refer to these as essay scores, much like the essay scores on the analytical writing section of the GRE. Scores were also dichotomized around a hypothetical cut score of 3, resulting in either a “Fail” or “Pass.”</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="reliability-study-designs.html#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate essay scores from two raters with a population </span></span>
<span id="cb40-2"><a href="reliability-study-designs.html#cb40-2" aria-hidden="true" tabindex="-1"></a><span class="co"># correlation of 0.90, and slightly different mean scores,</span></span>
<span id="cb40-3"><a href="reliability-study-designs.html#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="co"># with score range 0 to 6</span></span>
<span id="cb40-4"><a href="reliability-study-designs.html#cb40-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Note the capital T is an abbreviation for TRUE</span></span>
<span id="cb40-5"><a href="reliability-study-designs.html#cb40-5" aria-hidden="true" tabindex="-1"></a>essays <span class="ot">&lt;-</span> <span class="fu">rsim</span>(<span class="dv">100</span>, <span class="at">rho =</span> .<span class="dv">9</span>, <span class="at">meanx =</span> <span class="dv">4</span>, <span class="at">meany =</span> <span class="dv">3</span>,</span>
<span id="cb40-6"><a href="reliability-study-designs.html#cb40-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">sdx =</span> <span class="fl">1.5</span>, <span class="at">sdy =</span> <span class="fl">1.5</span>, <span class="at">to.data.frame =</span> T)</span>
<span id="cb40-7"><a href="reliability-study-designs.html#cb40-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(essays) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;r1&quot;</span>, <span class="st">&quot;r2&quot;</span>)</span>
<span id="cb40-8"><a href="reliability-study-designs.html#cb40-8" aria-hidden="true" tabindex="-1"></a>essays <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">setrange</span>(essays, <span class="at">to =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">6</span>)))</span>
<span id="cb40-9"><a href="reliability-study-designs.html#cb40-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Use a cut off of greater than or equal to 3 to determine</span></span>
<span id="cb40-10"><a href="reliability-study-designs.html#cb40-10" aria-hidden="true" tabindex="-1"></a><span class="co"># pass versus fail scores</span></span>
<span id="cb40-11"><a href="reliability-study-designs.html#cb40-11" aria-hidden="true" tabindex="-1"></a><span class="co"># ifelse() takes a vector of TRUEs and FALSEs as its first</span></span>
<span id="cb40-12"><a href="reliability-study-designs.html#cb40-12" aria-hidden="true" tabindex="-1"></a><span class="co"># argument, and returns here &quot;Pass&quot; for TRUE and &quot;Fail&quot; </span></span>
<span id="cb40-13"><a href="reliability-study-designs.html#cb40-13" aria-hidden="true" tabindex="-1"></a><span class="co"># for FALSE</span></span>
<span id="cb40-14"><a href="reliability-study-designs.html#cb40-14" aria-hidden="true" tabindex="-1"></a>essays<span class="sc">$</span>f1 <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">ifelse</span>(essays<span class="sc">$</span>r1 <span class="sc">&gt;=</span> <span class="dv">3</span>, <span class="st">&quot;Pass&quot;</span>, </span>
<span id="cb40-15"><a href="reliability-study-designs.html#cb40-15" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Fail&quot;</span>))</span>
<span id="cb40-16"><a href="reliability-study-designs.html#cb40-16" aria-hidden="true" tabindex="-1"></a>essays<span class="sc">$</span>f2 <span class="ot">&lt;-</span> <span class="fu">factor</span>(<span class="fu">ifelse</span>(essays<span class="sc">$</span>r2 <span class="sc">&gt;=</span> <span class="dv">3</span>, <span class="st">&quot;Pass&quot;</span>, </span>
<span id="cb40-17"><a href="reliability-study-designs.html#cb40-17" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;Fail&quot;</span>))</span>
<span id="cb40-18"><a href="reliability-study-designs.html#cb40-18" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(essays<span class="sc">$</span>f1, essays<span class="sc">$</span>f2)</span>
<span id="cb40-19"><a href="reliability-study-designs.html#cb40-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       </span></span>
<span id="cb40-20"><a href="reliability-study-designs.html#cb40-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        Fail Pass</span></span>
<span id="cb40-21"><a href="reliability-study-designs.html#cb40-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Fail   19    0</span></span>
<span id="cb40-22"><a href="reliability-study-designs.html#cb40-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Pass   27   54</span></span></code></pre></div>
<p>The upper left cell in the <code>table()</code> output above shows that for 19 individuals, the two raters both gave “Fail.” In the lower right cell, the two raters both gave “Pass” 54 times. Together, these two totals represent the agreement in ratings, 73 . The other cells in the table contain disagreements, where one rater said “Pass” but the other said “Fail.” Disagreements happened a total of 27 times. Based on these totals, what is the proportion agreement in the pass/fail ratings?</p>
<p>Table <a href="reliability-study-designs.html#tab:pa1">6.2</a> shows the full crosstab of raw scores from each rater, with scores from rater 1 (<code>essays$r1</code>) in rows and rater 2 (<code>essays$r2</code>) in columns. The bunching of scores around the diagonal from upper left to lower right shows the tendency for agreement in scores.</p>
<table>
<caption><span id="tab:pa1">Table 6.2: </span>Crosstab of Scores From Rater 1 in Rows and Rater 2 in Columns</caption>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">0</th>
<th align="right">1</th>
<th align="right">2</th>
<th align="right">3</th>
<th align="right">4</th>
<th align="right">5</th>
<th align="right">6</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">1</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">2</td>
<td align="right">5</td>
<td align="right">8</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">3</td>
<td align="right">0</td>
<td align="right">6</td>
<td align="right">11</td>
<td align="right">2</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">4</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">9</td>
<td align="right">9</td>
<td align="right">10</td>
<td align="right">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">5</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">6</td>
<td align="right">3</td>
<td align="right">1</td>
</tr>
<tr class="odd">
<td align="left">6</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">2</td>
<td align="right">3</td>
<td align="right">3</td>
<td align="right">10</td>
</tr>
</tbody>
</table>
<p>Proportion agreement for the full rating scale, as shown in Table <a href="reliability-study-designs.html#tab:pa1">6.2</a>, can be calculated by summing the agreement frequencies within the diagonal elements of the table, and dividing by the total number of people.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="reliability-study-designs.html#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Pull the diagonal elements out of the crosstab with </span></span>
<span id="cb41-2"><a href="reliability-study-designs.html#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="co"># diag(), sum them, and divide by the number of people</span></span>
<span id="cb41-3"><a href="reliability-study-designs.html#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">diag</span>(<span class="fu">table</span>(essays<span class="sc">$</span>r1, essays<span class="sc">$</span>r2))) <span class="sc">/</span> <span class="fu">nrow</span>(essays)</span>
<span id="cb41-4"><a href="reliability-study-designs.html#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.29</span></span></code></pre></div>
<p>Finally, let’s consider the impact of chance agreement between one of the hypothetical human raters and a monkey who randomly applies ratings, regardless of the performance that is demonstrated, as with a coin toss.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="reliability-study-designs.html#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Randomly sample from the vector c(&quot;Pass&quot;, &quot;Fail&quot;), </span></span>
<span id="cb42-2"><a href="reliability-study-designs.html#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="co"># nrow(essays) times, with replacement</span></span>
<span id="cb42-3"><a href="reliability-study-designs.html#cb42-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Without replacement, we&#39;d only have 2 values to sample </span></span>
<span id="cb42-4"><a href="reliability-study-designs.html#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="co"># from</span></span>
<span id="cb42-5"><a href="reliability-study-designs.html#cb42-5" aria-hidden="true" tabindex="-1"></a>monkey <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="st">&quot;Pass&quot;</span>, <span class="st">&quot;Fail&quot;</span>), <span class="fu">nrow</span>(essays),</span>
<span id="cb42-6"><a href="reliability-study-designs.html#cb42-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb42-7"><a href="reliability-study-designs.html#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(essays<span class="sc">$</span>f1, monkey)</span>
<span id="cb42-8"><a href="reliability-study-designs.html#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       monkey</span></span>
<span id="cb42-9"><a href="reliability-study-designs.html#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        Fail Pass</span></span>
<span id="cb42-10"><a href="reliability-study-designs.html#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Fail   10    9</span></span>
<span id="cb42-11"><a href="reliability-study-designs.html#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Pass   38   43</span></span></code></pre></div>
<p>The results show that the hypothetical rater agrees with the monkey 53 percent of the time. Because we know that the monkey’s ratings were completely random, we know that this proportion agreement is due entirely to chance.</p>
</div>
<div id="kappa-agreement" class="section level3" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Kappa agreement</h3>
<p>Proportion agreement is useful, but because it does not account for chance agreement, it should not be used as the only measure of interrater consistency. Kappa agreement is simply an adjusted form of proportion agreement that takes chance agreement into account.</p>
<p>Equation <a href="reliability-study-designs.html#eq:kappa1">(6.1)</a> contains the formula for calculating kappa for two raters.</p>
<p><span class="math display" id="eq:kappa1">\[\begin{equation}
\kappa = \frac{P_o - P_c}{1 - P_c}
\tag{6.1}
\end{equation}\]</span></p>
<p>To obtain kappa, we first calculate the proportion of agreement, <span class="math inline">\(P_o\)</span>, as we did with the proportion agreement. This is calculated as the total for agreement divided by the total number of people being rated. Next we calculate the chance agreement, <span class="math inline">\(P_c\)</span>, which involves multiplying the row and column proportions (row and column totals divided by the total total) from the crosstab and then summing the result, as shown in Equation <a href="reliability-study-designs.html#eq:kappa2">(6.2)</a>.</p>
<p><span class="math display" id="eq:kappa2">\[\begin{equation}
P_c = P_{first-row}P_{first-col} + P_{next-row}P_{next-col} + \dots + P_{last-row}P_{last-col}
\tag{6.2}
\end{equation}\]</span></p>
<p>You do not need to commit Equations <a href="reliability-study-designs.html#eq:kappa1">(6.1)</a> and <a href="reliability-study-designs.html#eq:kappa2">(6.2)</a> to memory. Instead, they’re included here to help you understand that kappa involves removing chance agreement from the observed agreement, and then dividing this observed non-chance agreement by the total possible non-chance agreement, that is, <span class="math inline">\(1 - P_c\)</span>.</p>
<p>The denominator for the kappa equation contains the maximum possible agreement beyond chance, and the numerator contains the actual observed agreement beyond chance. So, the maximum possible kappa is 1.0. In theory, we shouldn’t ever observe less agreement than than expected by chance, which means that kappa should never be negative. Technically it is possible to have kappa below 0. When kappa is below 0, it indicates that our observed agreement is below what we’d expect due to chance. Kappa should also be no larger than proportion agreement. In the example data, the proportion agreement decreased from 0.29 to 0.159 for kappa.</p>
<p>A weighted version of the kappa index is also available. Weighted kappa let us reduce the negative impact of partial disagreements relative to more extreme disagreements in scores, by taking into account the ordinal nature of a score scale. For example, in Table <a href="reliability-study-designs.html#tab:pa1">6.2</a>, notice that only the diagonal elements of the crosstab measure perfect agreement in scores, and all other elements measure disagreements, even the ones that are close together like 2 and 3. With weighted kappa, we can give less weight to these smaller disagreements and more weight to larger disagreements such as scores of 0 and 6 in the lower left and upper right of the table. This weighting ends up giving us a higher agreement estimate.</p>
<p>Here, we use the function <code>astudy()</code> from epmr to calculate proportion agreement, kappa, and weighted kappa indices. Weighted kappa gives us the highest estimate of agreement. Refer to the documentation for <code>astudy()</code> to see how the weights are calculated.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="reliability-study-designs.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the astudy() function from epmr to measure agreement</span></span>
<span id="cb43-2"><a href="reliability-study-designs.html#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="fu">astudy</span>(essays[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>])</span>
<span id="cb43-3"><a href="reliability-study-designs.html#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  agree  kappa wkappa </span></span>
<span id="cb43-4"><a href="reliability-study-designs.html#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.290  0.159  0.479</span></span></code></pre></div>
</div>
<div id="pearson-correlation" class="section level3" number="6.1.3">
<h3><span class="header-section-number">6.1.3</span> Pearson correlation</h3>
<p>The Pearson correlation coefficient, introduced above for CTT reliability, improves upon agreement indices by accounting for the ordinal nature of ratings without the need for explicit weighting. The correlation tells us how consistent raters are in their rank orderings of individuals. Rank orderings that are closer to being in agreement are automatically given more weight when determining the overall consistency of scores.</p>
<p>The main limitation of the correlation coefficient is that it ignores <em>systematic differences</em> in ratings when focusing on their rank orders. This limitation has to do with the fact that correlations are oblivious to linear transformations of score scales. We can modify the mean or standard deviation of one or both variables being correlated and get the same result. So, if two raters provide consistently different ratings, for example, if one rater is more forgiving overall, the correlation coefficient can still be high as long as the rank ordering of individuals does not change.</p>
<p>This limitation is evident in our simulated essay scores, where rater 2 gave lower scores on average than rater 1. If we subtract 1 point from every score for rater 2, the scores across raters will be more similar, as shown in Figure <a href="reliability-study-designs.html#fig:essays">6.1</a>, but we still get the same interrater reliability.</p>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="reliability-study-designs.html#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Certain changes in descriptive statistics, like adding </span></span>
<span id="cb44-2"><a href="reliability-study-designs.html#cb44-2" aria-hidden="true" tabindex="-1"></a><span class="co"># constants won&#39;t impact correlations</span></span>
<span id="cb44-3"><a href="reliability-study-designs.html#cb44-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(essays<span class="sc">$</span>r1, essays<span class="sc">$</span>r2)</span>
<span id="cb44-4"><a href="reliability-study-designs.html#cb44-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.854</span></span>
<span id="cb44-5"><a href="reliability-study-designs.html#cb44-5" aria-hidden="true" tabindex="-1"></a><span class="fu">dstudy</span>(essays[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>])</span>
<span id="cb44-6"><a href="reliability-study-designs.html#cb44-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-7"><a href="reliability-study-designs.html#cb44-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Descriptive Study</span></span>
<span id="cb44-8"><a href="reliability-study-designs.html#cb44-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb44-9"><a href="reliability-study-designs.html#cb44-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    mean median   sd   skew kurt min max   n na</span></span>
<span id="cb44-10"><a href="reliability-study-designs.html#cb44-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; r1 3.86      4 1.49 -0.270 2.48   0   6 100  0</span></span>
<span id="cb44-11"><a href="reliability-study-designs.html#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; r2 2.88      3 1.72  0.242 2.15   0   6 100  0</span></span>
<span id="cb44-12"><a href="reliability-study-designs.html#cb44-12" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(essays<span class="sc">$</span>r1, essays<span class="sc">$</span>r2 <span class="sc">+</span> <span class="dv">1</span>)</span>
<span id="cb44-13"><a href="reliability-study-designs.html#cb44-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.854</span></span></code></pre></div>
<p>A systematic difference in scores can be visualized by a consistent vertical or horizontal shift in the points within a scatter plot. Figure <a href="reliability-study-designs.html#fig:essays">6.1</a> shows that as scores are shifted higher for rater 2, they are more consistent with rater 1 in an absolute sense, despite the fact that the underlying linear relationship remains unchanged.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="reliability-study-designs.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparing scatter plots</span></span>
<span id="cb45-2"><a href="reliability-study-designs.html#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(essays, <span class="fu">aes</span>(r1, r2)) <span class="sc">+</span></span>
<span id="cb45-3"><a href="reliability-study-designs.html#cb45-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">position =</span> <span class="fu">position_jitter</span>(<span class="at">w =</span> .<span class="dv">1</span>, <span class="at">h =</span> .<span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb45-4"><a href="reliability-study-designs.html#cb45-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb45-5"><a href="reliability-study-designs.html#cb45-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(essays, <span class="fu">aes</span>(r1, r2 <span class="sc">+</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb45-6"><a href="reliability-study-designs.html#cb45-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">position =</span> <span class="fu">position_jitter</span>(<span class="at">w =</span> .<span class="dv">1</span>, <span class="at">h =</span> .<span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb45-7"><a href="reliability-study-designs.html#cb45-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<div class="figure"><span id="fig:essays"></span>
<img src="0200_CTT_files/figure-html/essays-1.png" alt="Scatter plots of simulated essay scores with a systematic difference around 0.5 points." width="50%" /><img src="0200_CTT_files/figure-html/essays-2.png" alt="Scatter plots of simulated essay scores with a systematic difference around 0.5 points." width="50%" />
<p class="caption">
Figure 6.1: Scatter plots of simulated essay scores with a systematic difference around 0.5 points.
</p>
</div>
<p>Is it a problem that the correlation ignores systematic score differences? Can you think of any real-life situations where it wouldn’t be cause for concern? A simple example is when awarding scholarships or giving other types of awards or recognition. In these cases consistent rank ordering is key and systematic differences are less important because the purpose of the ranking is to identify the top candidate. There is no absolute scale on which subjects are rated. Instead, they are rated in comparison to one another. As a result, a systematic difference in ratings would technically not matter.</p>
</div>
</div>
<div id="summary" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Summary</h2>
<p>This chapter provided an overview of reliability within the frameworks of CTT, for items and test forms, for reliability study designs with multiple facets. After a general definition of reliability in terms of consistency in scores, the CTT model was introduced, and two commonly used indices of CTT reliability were discussed: correlation and coefficient alpha. Reliability was then presented as it relates to consistency of scores from raters. Inter-rater agreement indices were compared, along with the correlation coefficient.</p>

</div>
</div>



<!--AE. Links-->
<!-- Lab Links-->
<!--Slides-->
<!--R Links-->
<!--RStudio Links-->
<!--HappyGitWithR Links-->
<!--Package Links-->
<!--Shiny links-->
<!--Publications-->
<!--R Documentation-->
<!--Wikipedia Links-->
<!--Misc. Links-->
</div>
            </section>

          </div>
        </div>
      </div>
<a href="r-code-and-readings-for-module-6.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="good-resources.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/DataScience4Psych/DataScience4Psych/edit/main/0200_CTT.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["https://github.com/DataScience4Psych/DataScience4Psych/raw/main/0200_CTT.Rmd", "DS4P.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
